<!-- 
Copyright 2005-2015, Foundations of Success, Bethesda, Maryland
on behalf of the Conservation Measures Partnership ("CMP").
Material developed between 2005-2013 is jointly copyright by Beneficent Technology, Inc. ("The Benetech Initiative"), Palo Alto, California.

This file is part of Miradi

Miradi is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License version 3, 
as published by the Free Software Foundation.

Miradi is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with Miradi.  If not, see <http://www.gnu.org/licenses/>.
-->

<div class='navigation'>
            
The <i>measurement</i> rating describes the indicator rating category where your key ecological attribute is today.

<P>The four-category framework for categorizing the viability status for each KEA and target provides little opportunity to describe and keep track of incremental changes.&nbsp;The data fields for both current and future status allow you to record information on incremental change in indicators. </P>

<P>There is a big difference between an indicator that currently&nbsp;has good status, but is rapidly decreasing, versus one that has good status, but is staying constant or increasing.&nbsp;It is thus often useful to display the&nbsp;<STRONG>trend</STRONG>&nbsp;in the indicator.&nbsp;It is also important to specify your confidence in the <b>source</b> of the	indicator.&nbsp;The confidence ratings are defined as follows:</P>

<UL>
<LI><STRONG>Rough Guess</STRONG> - Values are rough estimates by project team members. They are often an initial placeholder value meant to be improved down the road through use of other methods.</LI><br>
<LI><STRONG>Expert Knowledge</STRONG> - Values are more refined estimates provided by experienced, reliable observers who know the local project conditions, but are not basing their estimates on any specific data or observations. These experts may be project team members, professionals managers, researchers, or members of a traditional community that have reason to take note of the conditions of interest and the experience necessary to provide reliable information. This category also includes educated guesses made by extrapolating data from other similar sites.</LI><br>
<LI><STRONG>Rapid Assessment</STRONG> - Values are derived from data collected about this specific project area using relatively simple methods, including visual and auditory assessment. Data collection methods use protocols, field records and quality control procedures of varying degrees of standardization. They typically provide either presence/absence, categorical, or other qualitative measurements of indicator values, or rough quantitative measurements.</LI><br>
<LI><STRONG>Intensive Assessment</STRONG> - Values are derived from data collected about this specific project area using relatively detailed, quantitative methods. Data collection methods use standard protocols, field records and quality control procedures. They typically provide quantitative measurements of indicator values as well as an estimate of error. </LI></UL><br>

Note that both rapid and intensive assessments can include data collected by non-project staff, or even public data available on the internet - the key is that the data have to be about the project's specific site, targets, threats, and other factors, rather than extrapolating from other systems.
</div>
